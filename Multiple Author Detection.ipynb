{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataAggregator(path):\n",
    "    text_dict = {}\n",
    "    json_dict = {}\n",
    "    label_df = pd.DataFrame(columns=['changes', 'positions','file'])\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.txt'):\n",
    "            with open(path+file, 'r', encoding='utf-8') as myfile:\n",
    "                text_dict[file.replace('problem-', '').replace('.txt', '')] = myfile.read().replace('\\n', '')\n",
    "        else:\n",
    "            with open(path+file, 'r', encoding='utf-8') as myfile:\n",
    "                data = json.load(myfile)\n",
    "                json_dict[file.replace('problem-', '').replace('.truth', '')] = data['changes']\n",
    "\n",
    "    df = pd.DataFrame(list(text_dict.items()), columns=['file', 'text'])\n",
    "    label_df = pd.DataFrame(list(json_dict.items()), columns = ['file', 'changes'])\n",
    "\n",
    "    output_df = df.merge(label_df,on='file')\n",
    "    output_df = output_df.drop('file', axis = 1)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data sets to data frames\n",
    "test_df = DataAggregator('C:/Users/RSC/PyProjects/Data-Science/Data/pan18-style-change-detection-test-dataset-2018-01-31/')\n",
    "training_df = DataAggregator('C:/Users/RSC/PyProjects/Data-Science/Data/pan18-style-change-detection-training-dataset-2018-01-31/')\n",
    "validation_df = DataAggregator('C:/Users/RSC/PyProjects/Data-Science/Data/pan18-style-change-detection-validation-dataset-2018-01-31/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Text: 2980, Training Labels: 2980\n",
      "Test Text: 1352, Test Labels: 1352\n",
      "Validation Text: 1492, Validation Labels: 1492\n"
     ]
    }
   ],
   "source": [
    "#Split the data into text and labels\n",
    "training_labels = training_df['changes']\n",
    "validation_labels = validation_df['changes']\n",
    "test_labels = test_df['changes']\n",
    "\n",
    "training_text = list(training_df['text'])\n",
    "validation_text = list(validation_df['text'])\n",
    "test_text = list(test_df['text'])\n",
    "\n",
    "print(\"Training Text: \" + str(len(training_text)) + \", Training Labels: \" + str(len(training_labels)))\n",
    "print(\"Test Text: \" + str(len(test_text)) + \", Test Labels: \" + str(len(test_labels)))\n",
    "print(\"Validation Text: \" + str(len(validation_text)) + \", Validation Labels: \" + str(len(validation_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds a pipeline\n",
    "NB_pipeline = Pipeline([('vect', CountVectorizer(strip_accents = 'ascii', ngram_range=(1,5), analyzer='word', stop_words='english')),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('nb_clf', MultinomialNB())])\n",
    "\n",
    "SVC_pipeline = Pipeline([('vect', CountVectorizer(strip_accents = 'ascii', ngram_range=(1,5), analyzer='word', stop_words='english')),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('svc_clf', SVC())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find best parameters\n",
    "parameters = {'ngram_range': [(1,1), (1,2), (1,3), (1,4), (1,5)],\n",
    "              'tfidf': (True, False),\n",
    "              ''}\n",
    "\n",
    "nb_search = GridSearch(NB_pipeline, parameters, n_jobs=-1)\n",
    "nb_search = nb_search.fit(training_text, training_labels)\n",
    "\n",
    "svc_search = GridSearch(SVC_pipeline, parameters, n_jobs=-1)\n",
    "svc_search = svc_search.fit(training_text, training_labels)\n",
    "\n",
    "print(\"Best NB Score: \" ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.554959785523 -- Run time 25.458515405654907\n",
      "SVM Accuracy: 0.658847184987 -- Run time 114.53243255615234\n"
     ]
    }
   ],
   "source": [
    "#Train the models and fit to the validation set\n",
    "start = time.time()\n",
    "NB_pipeline.fit(training_text, training_labels)\n",
    "nb_prediction = NB_pipeline.predict(validation_text)\n",
    "print(\"Naive Bayes Accuracy: \" + str(accuracy_score(nb_prediction, validation_labels)) + \" -- Run time \" + str(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "SVC_pipeline.fit(training_text, training_labels)\n",
    "svc_prediction = SVC_pipeline.predict(validation_text)\n",
    "print(\"SVM Accuracy: \" + str(accuracy_score(svc_prediction, validation_labels)) + \" -- Run time \" + str(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
